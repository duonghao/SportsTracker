{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Pose Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import glob\n",
    "import pafy\n",
    "from tqdm import tqdm\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join, splitext\n",
    "from pathlib import Path\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/brian/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-12-19 Python-3.8.12 torch-1.12.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='./models/yolov5m.pt')  # or yolov5n - yolov5x6, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'N-RYJobvTes'\n",
    "# url = \"8QOcj0m21As\"\n",
    "# url = 'nM55YiDntno'\n",
    "# url ='MFYz7DCt9PI'\n",
    "# url = '6um-5sBEoMY'\n",
    "# url = 'PjIr-IbV5C4'\n",
    "# url = 'yObzW5imnRA'\n",
    "video = pafy.new(url)\n",
    "yt_video = video.getbest(preftype=\"mp4\")\n",
    "\n",
    "# # Video\n",
    "# video_path = './videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volleyball Poses Images Path\n",
    "crop_img_path = \"/Volumes/GoogleDrive-117429523964539289019/My Drive/vball_tracking/code/datasets/volleyball_poses\"\n",
    "\n",
    "# Sets Image Path\n",
    "sets_path = f'{crop_img_path}/sets'\n",
    "\n",
    "# Digs Image Path\n",
    "digs_path = f'{crop_img_path}/digs'\n",
    "\n",
    "# Spikes Image Path\n",
    "spikes_path = f'{crop_img_path}/spikes'\n",
    "\n",
    "# Others\n",
    "others_path = f'{crop_img_path}/others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file structure\n",
    "path = Path(digs_path)\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path = Path(spikes_path)\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path = Path(sets_path)\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path = Path(others_path)\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set up img numbering system\n",
    "if len(os.listdir(digs_path)) == 0:\n",
    "    digs_num = 0\n",
    "else:\n",
    "    digs_num = int(sorted(glob.glob(f'{digs_path}/*'))[-1][-10:][:-4])\n",
    "    \n",
    "if len(os.listdir(sets_path)) == 0:\n",
    "    sets_num = 0\n",
    "else:\n",
    "    sets_num = int(sorted(glob.glob(f'{sets_path}/*'))[-1][-10:][:-4])\n",
    "       \n",
    "if len(os.listdir(spikes_path)) == 0:\n",
    "    spikes_num = 0\n",
    "else:\n",
    "    spikes_num = int(sorted(glob.glob(f'{spikes_path}/*'))[-1][-10:][:-4])\n",
    "       \n",
    "if len(os.listdir(others_path)) == 0:\n",
    "    others_num = 0\n",
    "else:\n",
    "    others_num = int(sorted(glob.glob(f'{others_path}/*'))[-1][-10:][:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quit = False\n",
    "\n",
    "capture = cv2.VideoCapture(yt_video.url)\n",
    "\n",
    "_, image = capture.read()\n",
    "ims = []\n",
    "num_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(num_frames)\n",
    "\n",
    "nth_frame = 5\n",
    "\n",
    "for frame in range(1,num_frames//nth_frame):\n",
    "\n",
    "    if quit:\n",
    "        break\n",
    "    \n",
    "    for i in range(nth_frame):  \n",
    "        _, image = capture.read()\n",
    "\n",
    "    # inference\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = model(img_rgb)\n",
    "    dets = results.pandas().xyxy[0]\n",
    "\n",
    "    if not dets.empty:\n",
    "        # filter person\n",
    "        dets = dets.loc[dets['name'] == 'person']\n",
    "\n",
    "        # crop image by the bbox\n",
    "        for _, det in dets.iterrows():\n",
    "            crop_img = image[int(det.ymin):int(det.ymax), int(det.xmin):int(det.xmax)]\n",
    "            \n",
    "            if crop_img.shape[0] > 120 and crop_img.shape[1] > 60:\n",
    "                \n",
    "                output_frame = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Initialize fresh pose tracker and run it.\n",
    "                with mp_pose.Pose(upper_body_only=False) as pose_tracker:\n",
    "                    pose_result = pose_tracker.process(image=output_frame)\n",
    "                    pose_landmarks = pose_result.pose_landmarks\n",
    "                \n",
    "                # Draw pose to image\n",
    "                if pose_landmarks is not None:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=output_frame,\n",
    "                        landmark_list=pose_landmarks,\n",
    "                        connections=mp_pose.POSE_CONNECTIONS)\n",
    "                output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "                \n",
    "                cv2.imshow('cropped_images', output_frame)\n",
    "\n",
    "                key = cv2.waitKey(0)\n",
    "\n",
    "                if key == ord('q'):\n",
    "                    quit = True\n",
    "                    break\n",
    "                elif key == ord('d'):\n",
    "                    # Save as a 'dig'\n",
    "                    crop_img_name = f'{digs_path}/player_{digs_num:07d}.jpg'\n",
    "                    digs_num += 1\n",
    "                    cv2.imwrite(crop_img_name, crop_img)\n",
    "                elif key == ord('a'):\n",
    "                    # Save as a 'set'\n",
    "                    crop_img_name = f'{spikes_path}/player_{spikes_num:07d}.jpg'\n",
    "                    spikes_num += 1\n",
    "                    cv2.imwrite(crop_img_name, crop_img)\n",
    "                elif key == ord('s'):\n",
    "                    # Save as a 'set'\n",
    "                    crop_img_name = f'{sets_path}/player_{sets_num:07d}.jpg'\n",
    "                    sets_num += 1\n",
    "                    cv2.imwrite(crop_img_name, crop_img)\n",
    "                elif key == ord('o'):\n",
    "                    # Save as a 'other'\n",
    "                    crop_img_name = f'{others_path}/player_{others_num:07d}.jpg'\n",
    "                    others_num +=1\n",
    "                    cv2.imwrite(crop_img_name, crop_img)\n",
    "                elif key == ord('p'):\n",
    "                    # pass\n",
    "                    pass\n",
    "\n",
    "# After the loop release the cap object\n",
    "capture.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(image, dets):\n",
    "    for _, det in dets.iterrows():\n",
    "            image = cv2.rectangle(image, (int(det.xmin),int(det.ymin)), (int(det.xmax), int(det.ymax)), (0,255, 0), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9c032dcc91b613f37cc996d7f3ceda70ce17e143955d0b4f8a1151f022e8b86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
